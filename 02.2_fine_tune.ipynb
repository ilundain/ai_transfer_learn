{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_250x50.png?raw=true)\n",
    "***\n",
    "# *Practicum AI:* Transfer - Fine Tune\n",
    "\n",
    "This exercise adapted from Baig et al. (2020) <i>The Deep Learning Workshop</i> from <a href=\"https://www.packtpub.com/product/the-deep-learning-workshop/9781839219856\">Packt Publishers</a> (page 149).\n",
    "\n",
    "(7 - 10 Minutes)\n",
    "\n",
    "#### Introduction\n",
    "In the previous notebook, we learned how to apply transfer learning and use pretrained models to make predictions on our own dataset. With this approach, we froze the entire network and trained only the last few layers that were responsible for making the predictions. All the other layers stay the same, so all the filters are set in advance.  We are just reusing them.\n",
    "\n",
    "But if your dataset is dramatically different from ImageNet, these pretrained filters may not be relevant. In this case, basic transfer learning will not help your model accurately predict the right outcomes. Fortunately, there is a solution. Freeze only a portion of the network and train the rest of the model rather than just the top layers, as we do with basic transfer learning.\n",
    "\n",
    "In the early layers of the networks, the filters tend to be quite generic. For instance, you may find that these filters only detect horizontal or vertical lines. However, the filters closer to the end of the network (close to the top or head) are usually specific to the dataset you are training on. So, these are the ones we want to retrain. We will learn how to do that in this exercise.\n",
    "\n",
    "#### 1. Import requisite libraries and VGG16 model\n",
    "The VGG16 model is a variant of the VGG19 model we encountered in the hot dog transfer learning exercise.  Both models were trained on the famous ImageNet dataset.  A list of [pre-trained models](https://www.tensorflow.org/api_docs/python/tf/keras/applications) is available in the TensorFlow documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define the input dimensions of the images\n",
    "\n",
    "This is where you define the size of the images in *your* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (100, 100, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Instantiate the model\n",
    "\n",
    "We now instantiate the model.  The **include_top = False** parameter indicates that we will add a final prediction layer.  \n",
    "\n",
    "<div style=\"padding: 10px;margin-bottom: 20px;border: thin solid #30335D;border-left-width: 10px;background-color: #fff\"><strong>Note:</strong> You may encounter an error (often related to memory) when instantiating the model in this block. If that happens, restart the kernel and execute the blocks up to this point. That usually fixes the problem. </div>\n",
    "\n",
    "```python\n",
    "base_model = VGG16(input_shape = img_dim, weights = 'imagenet', \n",
    "                   include_top = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Define and set a variable of the layers to freeze\n",
    "\n",
    "Rather than freeze the entire model, we set the number of layers to freeze and assign it to variable.\n",
    "\n",
    "```python\n",
    "frozen_layers = 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Iterate through the layers and freeze them individually\n",
    "\n",
    "We then use a `for loop` to walk through those layers, freezing each one individually.\n",
    "\n",
    "```python\n",
    "for layer in base_model.layers[:frozen_layers]:\n",
    "    layer.trainable = False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Define a new prediction layer and append it to the model\n",
    "\n",
    "Because our hypothetical dataset contains 20 different kinds of images, we define a fully-connected (dense) layer with 20 units and a softmax activation function.  We then append our new prediction_layer to the model.\n",
    "\n",
    "```python\n",
    "prediction_layer = tf.keras.layers.Dense(20, activation = 'softmax')\n",
    "new_model = tf.keras.Sequential([base_model, prediction_layer])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Create an Adam optimizer and compile the model\n",
    "\n",
    "After this step, verify the model's architecture using the `.summary` method.\n",
    "\n",
    "```python\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "new_model.compile(loss = 'sparse_categorical_crossentropy', \n",
    "                  optimizer = optimizer, \n",
    "                  metrics   = ['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Fit (train) the model\n",
    "\n",
    "<div style=\"padding: 10px;margin-bottom: 20px;border: thin solid #30335D;border-left-width: 10px;background-color: #fff\"><strong>Note:</strong> The code in the next block is for demonstration purposes only as the features_train and label_train variables are undefined.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.fit(features_train, label_train, epochs = 5, validation_split = 0.2, verbose = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.4.1",
   "language": "python",
   "name": "tensorflow-2.4.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
